{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Retail Sales Pridiction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** - Syed Junaid Ali"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann Sales Dataset** - Rossmann Stores is a live dataset. During analysis of this dataset i observe that Rossmann dataset is a regression problem and our main goal is to predict the sales figures of Rossmann problem. In this Notebook i work on the following topics.\n",
        "\n",
        "First of all i'll do some Exploratory Data Analysis to Analyse the Dataset. Analyse Trends and Seasonality in Rossmann dataset by Using Exponential Moving Averages.\n",
        "\n",
        "Using following regeression models to predict the target:\n",
        "\n",
        "1). Linear Regression\n",
        "\n",
        "2). Lasso and Ridge Regression with cross validation(Grid search CV).\n",
        "\n",
        "3). Random Forest Regression."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality and locality. With thousands of individual managers predicting sales based on their unique Li lances, the accuracy of results can be quite varied.\n",
        "\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set.Note that some stores in the dataset were temporarily closed for refurbishment."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Knowing our Dataset***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
        "import math\n",
        "import itertools\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"/content/drive/MyDrive/regression datasets/\"\n",
        "Rossmann_store_df = pd.read_csv(filepath + 'Copy of Copy of Rossmann Stores Data.csv')\n",
        "store_df = pd.read_csv(filepath + 'Copy of Copy of store.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "Rossmann_store_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.head()"
      ],
      "metadata": {
        "id": "u594D8LpMzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "Rossmann_store_df.shape,store_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Rossmann_store_df are having 1017209 rows and 9 columns.\n",
        "* store_df are having 1115 rows and 10 columns."
      ],
      "metadata": {
        "id": "T_9putrFKPLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Rossmann_store_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()"
      ],
      "metadata": {
        "id": "xz5yUo_MPJw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(Rossmann_store_df[Rossmann_store_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(store_df[store_df.duplicated()])"
      ],
      "metadata": {
        "id": "7ALQON26P4Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "Rossmann_store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_columns = store_df[store_df.columns].isnull().sum()\n",
        "null_columns"
      ],
      "metadata": {
        "id": "hh5xFYONJLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_columns = store_df[store_df.columns].isnull().sum()\n",
        "percentage_missing_values = round(null_columns*100/store_df.count()[0],2)\n",
        "percentage_missing_values"
      ],
      "metadata": {
        "id": "bSZ2tlOJV8dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,5))\n",
        "percentage_missing_values.plot(kind = 'bar')\n",
        "plt.title(\"Percentage of Missing Values\")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are lots of null values found in this datataset.Having 3 missing values in **CompetitionDistance** , 345 missing values in **CompetitionOpenSinceMonth**, 345 missing values in **CompetitionOpenSinceYear**, 544 missing values in **Promo2SinceWeek**, 544 missing values in **Promo2SinceYear**, 544 missing values in **PromoInterval**. We can fill the null values further accordingly."
      ],
      "metadata": {
        "id": "vOp56_gPbX0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_store_df = store_df.copy()\n",
        "\n",
        "#Replacing Nan values with mean.\n",
        "mean_CompetitionDistance = new_store_df['CompetitionDistance'].mean()\n",
        "new_store_df['CompetitionDistance'] = new_store_df['CompetitionDistance'].fillna(mean_CompetitionDistance)"
      ],
      "metadata": {
        "id": "Ul8lSFfoZSUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing Nan values with mode.\n",
        "mode_CompetitionOpenSinceMonth = new_store_df['CompetitionOpenSinceMonth'].mode().iloc[0]\n",
        "new_store_df['CompetitionOpenSinceMonth'] = new_store_df['CompetitionOpenSinceMonth'].fillna(mode_CompetitionOpenSinceMonth)"
      ],
      "metadata": {
        "id": "iHC69ZfTZMZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CompetitionOpenSinceYear_mode = new_store_df['CompetitionOpenSinceYear'].mode().iloc[0]\n",
        "new_store_df['CompetitionOpenSinceYear'] = new_store_df['CompetitionOpenSinceYear'].fillna(CompetitionOpenSinceYear_mode)"
      ],
      "metadata": {
        "id": "LOGDnsURZHvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Promo2SinceWeek_mode = new_store_df['Promo2SinceWeek'].mode().iloc[0]\n",
        "new_store_df['Promo2SinceWeek'] = new_store_df['Promo2SinceWeek'].fillna(Promo2SinceWeek_mode)"
      ],
      "metadata": {
        "id": "IZvRxLylZCSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Promo2SinceYear_mode = new_store_df['Promo2SinceYear'].mode().iloc[0]\n",
        "new_store_df['Promo2SinceYear'] = new_store_df['Promo2SinceYear'].fillna(Promo2SinceYear_mode)"
      ],
      "metadata": {
        "id": "QCoxuhRDYy9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PromoInterval_mode = new_store_df['PromoInterval'].mode().iloc[0]\n",
        "new_store_df['PromoInterval'] = new_store_df['PromoInterval'].fillna(PromoInterval_mode)\n",
        "new_store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "g56bLgE8yzkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming categorical features to numerical values.\n",
        "new_store_df['StoreType'] = new_store_df['StoreType'].map({'a':0,'b':1,'c':2,'d':3})\n",
        "new_store_df['Assortment'] = new_store_df['Assortment'].map({'a':1,'b':2,'c':3})\n",
        "new_store_df['PromoInterval'] = new_store_df['PromoInterval'].map({'Jan,Apr,Jul,Oct' : 1,'Feb,May,Aug,Nov': 2,'Mar,Jun,Sept,Dec': 3})"
      ],
      "metadata": {
        "id": "5NhxTlKgZYab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_store_df"
      ],
      "metadata": {
        "id": "GM-KmUiRe2j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets merge both datasets.\n",
        "main_store_df  = pd.merge(Rossmann_store_df,new_store_df,how = 'left', on = 'Store')\n",
        "main_store_df.head()"
      ],
      "metadata": {
        "id": "Xck7bTCVSDif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df.shape"
      ],
      "metadata": {
        "id": "4r7e8pYiUJ94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann Stores Data.csv** - Previous data including target variable(sales)\n",
        "\n",
        "**store.csv** - Having additional information about stores\n",
        "\n",
        "**Features**\n",
        "\n",
        "- Id - an Id that represents a (Store, Date) duple within the test set\n",
        "\n",
        "- Store - a unique Id for each store(integer)\n",
        "\n",
        "- Sales(Target variable) - the sales for any given day (this is what you are predicting for)(numeric)\n",
        "\n",
        "- Customers - indicates the total number of customers on a given day(numeric)\n",
        "\n",
        "- Open - indicates whether the store was open: 0 = closed, 1 = open(categorical)\n",
        "\n",
        "- StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None(categorical)\n",
        "\n",
        "- SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools(categoical)\n",
        "\n",
        "- StoreType - having different types of  stores like a, b, c, d(categorical)\n",
        "\n",
        "- Assortment - having different types of  assortment level: a = basic, b = extra, c = extended(categorical)\n",
        "\n",
        "- CompetitionDistance - having distance in meters to the nearest competitor store(numeric)\n",
        "\n",
        "- CompetitionOpenSince[Month/Year] - gives the approximate year and month in Which the nearest competitor was opened(numeric)\n",
        "\n",
        "- Promo - indicates whether a store is running a promo on that day(categotical)\n",
        "\n",
        "- Promo2 - indicates that store running consecutive promotions or not in which 0 = store is not participating, 1 = store is participating(categorical)\n",
        "\n",
        "- Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2(numeric)\n",
        "\n",
        "- PromoInterval - describes the consecutive intervals when Promo2 is started, naming the months of the promotion is started a new. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store.(categorical)\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Understanding the Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "main_store_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "main_store_df.describe().apply(lambda x: x.apply('{0:.2f}'.format))"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df.info()"
      ],
      "metadata": {
        "id": "G4cMZWT2gcwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df['StateHoliday'].value_counts()"
      ],
      "metadata": {
        "id": "behP8Gi_UrA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming categorical features to numerical values.\n",
        "main_store_df.loc[main_store_df['StateHoliday'] == '0', 'StateHoliday'] = 0\n",
        "main_store_df.loc[main_store_df['StateHoliday'] == 'a', 'StateHoliday'] = 1\n",
        "main_store_df.loc[main_store_df['StateHoliday'] == 'b', 'StateHoliday'] = 2\n",
        "main_store_df.loc[main_store_df['StateHoliday'] == 'c', 'StateHoliday'] = 3\n",
        "main_store_df['StateHoliday'] = main_store_df['StateHoliday'].astype(int, copy = False)\n",
        "print('Unique -', main_store_df['StateHoliday'].unique(), '; Data Type -', main_store_df['StateHoliday'].dtype)"
      ],
      "metadata": {
        "id": "HDff0dbc1tLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming categorical features to numerical values.\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'a', 'Assortment'] = 1\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'b', 'Assortment'] = 2\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'c', 'Assortment'] = 3\n",
        "main_store_df['Assortment'] = main_store_df['Assortment'].astype(int, copy = False)\n",
        "print('Unique -', main_store_df['Assortment'].unique(), '; Data Type -', main_store_df['Assortment'].dtype)"
      ],
      "metadata": {
        "id": "xB5gt9KeniJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming categorical features to numerical values.\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'a', 'Assortment'] = 1\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'b', 'Assortment'] = 2\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'c', 'Assortment'] = 3\n",
        "main_store_df.loc[main_store_df['Assortment'] == 'd', 'Assortment'] = 4\n",
        "main_store_df['Assortment'] = main_store_df['Assortment'].astype(int, copy = False)\n",
        "print('Unique -', main_store_df['Assortment'].unique(), '; Data Type -', main_store_df['Assortment'].dtype)\n"
      ],
      "metadata": {
        "id": "3tTvnOdSo6Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing format of date from object to datetime\n",
        "main_store_df['Date'] = pd.to_datetime(main_store_df['Date'], format= '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "bJ-NXWCBv6YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df['CompetitionOpenSinceYear']= main_store_df['CompetitionOpenSinceYear'].astype(int)\n",
        "main_store_df['Promo2SinceYear']= main_store_df['Promo2SinceYear'].astype(int)"
      ],
      "metadata": {
        "id": "Vkze9TjywgVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df['CompetitionOpenSinceMonth'] = pd.DatetimeIndex(main_store_df['Date']).month"
      ],
      "metadata": {
        "id": "2UeL4bCtxOUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df['CompetitionDistance']= main_store_df['CompetitionDistance'].astype(int)\n",
        "main_store_df['Promo2SinceWeek']= main_store_df['Promo2SinceWeek'].astype(int)"
      ],
      "metadata": {
        "id": "OoMw7Z2MxeyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "5LRBHlISH7l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Depending variable \"Sales\".\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(main_store_df['Sales'],color=\"y\")"
      ],
      "metadata": {
        "id": "_fqWqkPXhATf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(main_store_df['Sales'].apply(math.sqrt),color=\"y\")"
      ],
      "metadata": {
        "id": "Ekgm_2eAhuyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# having sales(target variable) is 0 with store not open.\n",
        "main_store_df[(main_store_df.Sales == 0) & (main_store_df.Open == 0)]"
      ],
      "metadata": {
        "id": "ct2ZBEegoXvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, there are lots of rows which are having 0 value in Sales column because of store not open due to some reason."
      ],
      "metadata": {
        "id": "A9yS8Y1PNgEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric features\n",
        "numeric_features = main_store_df.describe().columns"
      ],
      "metadata": {
        "id": "5CB9CNb0szGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of numeric features.\n",
        "for col in numeric_features[1:]:\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "  ax = fig.gca()\n",
        "  feature = main_store_df[col]\n",
        "  feature.hist(bins=50, ax = ax)\n",
        "  ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwrlLGsCtPZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By plotting above graphs we see that there are so many features which are not noramaly distributed.We can transform them later."
      ],
      "metadata": {
        "id": "flNzhqwVTq3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df.columns"
      ],
      "metadata": {
        "id": "5NqqSPbHTk1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trend_cols = ['CompetitionOpenSinceYear','Promo2SinceYear','CompetitionOpenSinceMonth','DayOfWeek']"
      ],
      "metadata": {
        "id": "qx6JfjNXZCdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trend of sales during the period of time.**"
      ],
      "metadata": {
        "id": "z-riXRmd171p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in trend_cols[:]:\n",
        "  fig = plt.figure(figsize=(15, 6))\n",
        "  ax = fig.gca()\n",
        "  #feature = main_store_df[col]\n",
        "  sns.pointplot(x= col, y= 'Sales', data=main_store_df)\n",
        "\n",
        "  ax.set_title(col + ' vs Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cCilxi-jXUGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **CompetitionOpenSinceYear vs Sales** - the above graph shows the relation between CompetitionOpenSinceYear and Sales that more sales are made in the year of 1900 when there is less competition, as year increases the new competitor stores comes into place which results in declined in sales.\n",
        "\n",
        "- **Promo2SinceYear vs Sales** - the above graph shows the relation between Promo2SinceYear and Sales it effect the sales but intead of doing promo in the year of 2012 and 2013 sales will increased.\n",
        "\n",
        "- **CompetitionOpenSinceMonth vs Sales** - the above graph shows the relation between CompetitionOpenSinceMonth and Sales that sales are high in the month of January, March, May, June, August in comparision to other months.\n",
        "\n",
        "- **DayOfWeek vs sales** - the above graph shows the relation between DayOfWeek and Sales as the sales are high on Monday in comparision to other days of week and on Saturday and Sunday sales have decreased almost near to zero because some store are closed on these day."
      ],
      "metadata": {
        "id": "y1fmTcdWa-k0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Barplot for categorical columns.**"
      ],
      "metadata": {
        "id": "4tVcWWU62m1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['StoreType','Assortment','Promo','StateHoliday','SchoolHoliday']:\n",
        "  fig = plt.figure(figsize=(8, 6))\n",
        "  ax = fig.gca()\n",
        "  sns.barplot(x= col, y= 'Sales', data=main_store_df)\n",
        "  ax.set_title(col + ' vs Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_eZboj9BskF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **StoreType vs Sales** - Above graph shows that store 1 has the maximum sales followed by other stores.\n",
        "- **Assortment vs Sales** - As per the above graph we found that assortment 2 are having maximum sales in all stores.\n",
        "- **Promo vs Sales**  = In Promo we have only 0 = not doing promos and 1 = doing promos,so we found the store who are continuously doing promos are have more sales than the stored who are not doing promos.\n",
        "- **StateHoliday** - In this we three categories 0 = Public holiday, 1 = Easter holiday, 2 = Christmas, 3 = None we observe that stores are mainly closed on Public holiday's only.\n",
        "- **SchoolHoliday** - We have 0 = stores closed on school holiday and 1 = stores open on school holiday as we can see above that store open on school holiday's are having more sales than normal."
      ],
      "metadata": {
        "id": "xDEaqmTErtk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(Rossmann_store_df,store_df,how = 'left', on = 'Store')"
      ],
      "metadata": {
        "id": "RdYwArsA3Bsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2,figsize=(15,10) )\n",
        "palette = itertools.cycle(sns.color_palette(n_colors=4))\n",
        "plt.subplots_adjust(hspace = 0.28)\n",
        "axes[0,0].bar(merged_df.groupby(by=\"StoreType\").count().Store.index ,merged_df.groupby(by=\"StoreType\").count().Store)\n",
        "axes[0,0].set_title(\"Number of Stores per Store Type \\n Fig 1.1\")\n",
        "axes[0,1].bar(merged_df.groupby(by=\"StoreType\").sum().Store.index,merged_df.groupby(by=\"StoreType\").sum().Sales/1e9)\n",
        "axes[0,1].set_title(\"Total Sales per Store Type \\n Fig 1.2\")\n",
        "axes[1,0].bar(merged_df.groupby(by=\"StoreType\").sum().Customers.index,merged_df.groupby(by=\"StoreType\").sum().Customers/1e6)\n",
        "axes[1,0].set_title(\"Total Number of Customers per Store Type (in Millions) \\n Fig 1.3\")\n",
        "axes[1,1].bar(merged_df.groupby(by=\"StoreType\").sum().Customers.index,merged_df.groupby(by=\"StoreType\").Sales.mean())\n",
        "axes[1,1].set_title(\"Average Sales per Store Type \\n Fig 1.4\")\n",
        "plt.show()\n",
        "print('Store type count \\n', store_df['StoreType'].value_counts().sort_values())"
      ],
      "metadata": {
        "id": "1GkbJnth7cBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As per the above plots we observe that 'a' type of stores and customers are having maximum count followed by other store types and 'b' type of stores and customers are having least count.\n",
        "- We also observe that b type of stores are having highest average sales per customer followed by the other stores."
      ],
      "metadata": {
        "id": "vPR68updlAvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count of Promo's per Store Type**"
      ],
      "metadata": {
        "id": "SW28ZhURftl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Promos per Store Type\n",
        "count_ = sns.countplot(x=\"StoreType\", hue = \"Promo\",order = ['a','b','c','d'], data=merged_df,palette=sns.color_palette(n_colors=3)).set_title(\"Number of Promo per Store Type\")\n",
        "merged_df.groupby(by=[\"StoreType\",\"Promo\"]).Promo.count()"
      ],
      "metadata": {
        "id": "AHPiRBklZVCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different types of Assortment with respect to store type**\n",
        "\n",
        "a = common things\n",
        "b = extra things\n",
        "c = highest variety of products"
      ],
      "metadata": {
        "id": "RHQ_Gmo0hRTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Different types of Assortment count per Store Type\n",
        "count_ = sns.countplot(x=\"StoreType\", hue = \"Assortment\",order = ['a','b','c','d'], data=merged_df,palette=sns.color_palette(n_colors=3)).set_title(\"Different types of Assortment count per Store Type\")\n",
        "merged_df.groupby(by=[\"StoreType\",\"Assortment\"]).Assortment.count()"
      ],
      "metadata": {
        "id": "4R9FX1QJdTRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that the stores are mainly having 'a' and 'c' type of assortments are in high demand."
      ],
      "metadata": {
        "id": "TwxWFJpctHtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "UtCO0kPV_2Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clonclusions of EDA**\n",
        "\n",
        "- There are two datasets - a) Rossmann.csv & b) Store.csv\n",
        "- shape of Rossmann dataset = (1017209,8), shape of store dataset = (1115, 10)\n",
        "- On looking on datasets we found lots of Nan values in Store dataset.\n",
        "- replaced null values with suitable values. In CompetitionDistance column only\n",
        "  3 Nan values are there. So we replaced it with mean.\n",
        "- Also Having null values in CompetitionOpenSinceMonth,\n",
        "  CompetitionOpenSinceYear,Promo2SinceWeek,Promo2SinceYear, so i replacedd it with mode.\n",
        "- In both dataset 'Store' column is common. So i do inner join on the basis of column 'Store'.\n",
        "- there are columns 'StateHoliday', 'SchoolHoliday' & 'Assortment' with object data types so i change these to int data type."
      ],
      "metadata": {
        "id": "6UjuM_3D4Zlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features"
      ],
      "metadata": {
        "id": "yxFi0I_OFjG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation**"
      ],
      "metadata": {
        "id": "hHJ6cE-Dr6e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features_1 = [x for x in numeric_features if x not in ['Store','Sales','StoreType','Assssorment','PromoInterval']]\n",
        "numeric_features_1"
      ],
      "metadata": {
        "id": "lXqM55cEEOXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_features_1[0:-1]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = main_store_df[col]\n",
        "    label = main_store_df['Sales']\n",
        "    corr_ = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Sales')\n",
        "    ax.set_title('Sales vs ' + col + '- correlation: ' + str(corr_))\n",
        "    z = np.polyfit(main_store_df[col], main_store_df['Sales'], 1)\n",
        "    y_hat = np.poly1d(z)(main_store_df[col])\n",
        "\n",
        "    plt.plot(main_store_df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation\n",
        "plt.figure(figsize=(18,8))\n",
        "correlation = main_store_df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "K_Yy4F-Suo5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multicolinearity**"
      ],
      "metadata": {
        "id": "DwUK4IXFvtzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calculate_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "UdLe_s8evpXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_vif(main_store_df[[x for x in main_store_df.describe().columns if x not in ['Sales']]])"
      ],
      "metadata": {
        "id": "Zf19eynYwW0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicolinearity of CompetitionOpenSinceYear column is high so we decided to drop it."
      ],
      "metadata": {
        "id": "j9pGippVyyIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_vif(main_store_df[[x for x in main_store_df.describe().columns if x not in ['Sales','CompetitionOpenSinceYear']]])"
      ],
      "metadata": {
        "id": "MJVrhi_mw_A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicolinearity of Promo2SinceYear column is high so we decided to drop it."
      ],
      "metadata": {
        "id": "yc6sJ1kKzkQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_vif(main_store_df[[x for x in main_store_df.describe().columns if x not in ['Sales','CompetitionOpenSinceYear','Promo2SinceYear']]])\n"
      ],
      "metadata": {
        "id": "V-OEDbiByMEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the Variance Inflation Factor(VIF) is less that 10.It looks quite well."
      ],
      "metadata": {
        "id": "qlRR5O-ezrcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lets deal with dependent variable(Sales) having 0 value.**"
      ],
      "metadata": {
        "id": "drEEigre0ZEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the saled column where values are 0.\n",
        "main_store_df[(main_store_df  .Open == 0) & (main_store_df.Sales == 0)].count()[0]"
      ],
      "metadata": {
        "id": "N0MYNX3402eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have total **172817** values in sales column which is 0.It means type store is temporarily closed.So i decided to drop these rows."
      ],
      "metadata": {
        "id": "0n0p03HX25OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the values.\n",
        "model_df = main_store_df.drop(main_store_df[(main_store_df  .Open == 0) & (main_store_df.Sales == 0)].index)"
      ],
      "metadata": {
        "id": "7QktLNcH2UCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new shape\n",
        "model_df.shape"
      ],
      "metadata": {
        "id": "Wwp9cgqy2y-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the variable into dummies.\n",
        "model_df = pd.get_dummies(model_df, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "5f1slALP2y48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df.head()"
      ],
      "metadata": {
        "id": "tbxTcArR4gOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Model(excluding Sales = 0)**"
      ],
      "metadata": {
        "id": "NegLqdvk5as-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dependent_variables = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "independent_variables = list(model_df.columns.drop(['CompetitionOpenSinceMonth','Promo2SinceYear','Date','Sales']))"
      ],
      "metadata": {
        "id": "FpkJIr_z5Zkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables"
      ],
      "metadata": {
        "id": "ek8YbIwI6I0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore"
      ],
      "metadata": {
        "id": "9eY04texCdaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "X = model_df[independent_variables].values\n",
        "\n",
        "# Create the data of dependent variable\n",
        "Y = model_df[dependent_variables].values"
      ],
      "metadata": {
        "id": "Nmca0m-o6nLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X,Y , test_size = 0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "FWrMAKCWDWuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "GcGP_Zwah3Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "n2J3wV5G66Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "_RtUVWoO7Blv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "QrTpci8liQ7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "ITYDMODtidOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_avg = model_df[dependent_variables].mean()"
      ],
      "metadata": {
        "id": "_-bsaiApmnXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#Model Evaluation\n",
        "MSE  = mean_squared_error(Y_test,y_pred) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "UaeoSuXcioBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "#Coefficient of determination\n",
        "r2 = r2_score(Y_test, y_pred) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n"
      ],
      "metadata": {
        "id": "zunlDhEpj1dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(Y_test, y_pred, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(y_pred), max(Y_test))\n",
        "p2 = min(min(y_pred), min(Y_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Kc29rUwAUFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression**"
      ],
      "metadata": {
        "id": "adWECatMpn1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso  = Lasso(alpha=0.1 , max_iter= 3000)\n",
        "\n",
        "lasso.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Ntufl1Idpnfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "qhuRQ_upqsnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_l = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "OCmJjnEpq5mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "MSE  = mean_squared_error(Y_test,y_pred_l) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "hT4NX41rsXeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coffiecient of dtermination\n",
        "r2 = r2_score(Y_test,y_pred_l) # R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "q3Gtsj6Bst17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "###  Hyperparameter Tuning & Cross validation\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "JBqiU2Se0KI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "5lpNFfDy8riP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "GvSc2Pj09CfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(Y_test,y_pred_lasso) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "IOP1K3RZ-CJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coefficient of dtermiation\n",
        "r2 = r2_score(Y_test,y_pred_lasso) # R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "LgQAV4V_-iuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(Y_test, y_pred_lasso, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(y_pred_lasso), max(Y_test))\n",
        "p2 = min(min(y_pred_lasso), min(Y_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QuKz1yMrBX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge regression**"
      ],
      "metadata": {
        "id": "HeQXCNvfz_K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge  = Ridge(alpha=0.1)"
      ],
      "metadata": {
        "id": "hsH9nL9Iz-x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "sQYLfz8t_xTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(X_train,Y_train)"
      ],
      "metadata": {
        "id": "BEMWugHe_4Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "TWUumxTOASJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "MSE  = mean_squared_error(Y_test,y_pred_ridge) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "gF5RWlrKAYxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coefficient of determination\n",
        "r2 = r2_score(Y_test,y_pred_ridge) # R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "21Wr9RX1Avy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperprarameter tuning & Cross validation\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "GvNjjuVUBc4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "iYSKRCHUCZEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Prediction\n",
        "y_pred_r = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "W-0MLssjCi7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation.\n",
        "MSE  = mean_squared_error(Y_test,y_pred_r) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "E9K-1libCOjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coefficient of determination\n",
        "r2 = r2_score(Y_test,y_pred_r)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "ZwoxMrUXC891"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(Y_test, y_pred_r, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(y_pred_r), max(Y_test))\n",
        "p2 = min(min(y_pred_r), min(Y_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bx2QZU1cDwmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "xrm_NsM0o5np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "vH-TA2nMo5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dt = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "0j5UB8PJpR11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_dt = decision_tree.predict(X_train)"
      ],
      "metadata": {
        "id": "XSr1R13bpT6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation.\n",
        "MSE  = mean_squared_error(Y_test,y_pred_dt) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\" ,RMPSE)"
      ],
      "metadata": {
        "id": "JAuq5ki05kPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coefficient of determination\n",
        "r2 = r2_score(Y_test,y_pred_dt) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,y_pred_dt))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "Sattw6kg7Lkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(Y_test, y_pred_dt, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(y_pred_dt), max(Y_test))\n",
        "p2 = min(min(y_pred_dt), min(Y_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QnAFDpOLIG2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2 (including all the observations of Sales)**"
      ],
      "metadata": {
        "id": "9_j19CpNMfL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reviewing the dataset\n",
        "main_store_df"
      ],
      "metadata": {
        "id": "UGT67tOoMPkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now first of all we have make dummies of '**PromoInteval**' column."
      ],
      "metadata": {
        "id": "_JId3KzzM8jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df =  pd.get_dummies(main_store_df, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "deUq007eNRei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df.head()"
      ],
      "metadata": {
        "id": "ZXnE7F1xREa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df.shape"
      ],
      "metadata": {
        "id": "VU0WyIHcRKW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets define dependent and independent variables and convert them into arrays\n",
        "# defining dependent variable\n",
        "dep_var = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "indep_var = main_store_df.columns.drop(['Store', 'Promo2SinceYear','Date','Sales'])"
      ],
      "metadata": {
        "id": "TqJg5fUVRZbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = main_store_df[indep_var].values\n",
        "v = main_store_df[dep_var].values"
      ],
      "metadata": {
        "id": "k-gwYFcjR1XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_store_df[indep_var]"
      ],
      "metadata": {
        "id": "XtHY15TTSemM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dooing train-test split considering test size 0.30."
      ],
      "metadata": {
        "id": "cU0Q3b0-WwPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "u_train, u_test, v_train, v_test = train_test_split(u, v, test_size=0.30, random_state = 0)\n",
        "print(u_train.shape)\n",
        "print(u_test.shape)"
      ],
      "metadata": {
        "id": "Nh05zSD_WZRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "7YP6nkBYXRt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the u values\n",
        "scaler=StandardScaler()\n",
        "\n",
        "u_train = scaler.fit_transform(u_train)\n",
        "u_test = scaler.transform(u_test)"
      ],
      "metadata": {
        "id": "yr5yNEHQXQxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data into Lineat Regression Model\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(u_train, v_train)"
      ],
      "metadata": {
        "id": "I-P2EFZzY_lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting now\n",
        "v_pred=linear_reg.predict(u_test)\n",
        "v_pred"
      ],
      "metadata": {
        "id": "01yo6VzoZPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg.score(u_train,v_train)"
      ],
      "metadata": {
        "id": "Tm2hBsXfZ1_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg.score(u_test,v_test)\n"
      ],
      "metadata": {
        "id": "1gn75VzbaOUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_Dataframe = pd.DataFrame(zip(v_test, v_pred), columns = ['actual', 'pred'])\n",
        "reg_Dataframe"
      ],
      "metadata": {
        "id": "rM8pSV7pJ0g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "TeKt5QSFKDyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(v_test, v_pred, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(v_pred), max(v_test))\n",
        "p2 = min(min(v_pred), min(v_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "II0SUUPBJ2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression**"
      ],
      "metadata": {
        "id": "CjyNIhhiNbIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=1.0)"
      ],
      "metadata": {
        "id": "3TE_qtEnNYX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.fit(u_train, v_train)"
      ],
      "metadata": {
        "id": "weTItmaPNojC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_lasso = lasso.predict(u_test) #prediction"
      ],
      "metadata": {
        "id": "mWJcV-kTNupv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(u_train, v_train) #lasso score"
      ],
      "metadata": {
        "id": "HzdOgLWxN2Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(v_test, v_pred_lasso), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "fG1-fs85N5Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_lasso) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_lasso) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "fdyMQ97OOcl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hyperparameter tuning & Cross validation\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(u_train,v_train)"
      ],
      "metadata": {
        "id": "oe0tIBAqVTst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "18hnKTzuWtFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_lass = lasso_regressor.predict(u_test) # prediction"
      ],
      "metadata": {
        "id": "uCuc5kCIX_dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_lass) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_lass) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_lass))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "eGxes1zEYaLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(v_test, v_pred_lass, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(v_pred_lass), max(v_test))\n",
        "p2 = min(min(v_pred_lass), min(v_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6gqguF_PU4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Rergression**"
      ],
      "metadata": {
        "id": "Hj3cpKldZHPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=0.5)"
      ],
      "metadata": {
        "id": "iqA2gtI5ZGeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(u_train, v_train)"
      ],
      "metadata": {
        "id": "JAV5toMgZge4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_rid=ridge.predict(u_test)"
      ],
      "metadata": {
        "id": "PBlo8SmAZkcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(u_test, v_test)"
      ],
      "metadata": {
        "id": "a_QjYJbtZvmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(v_test, v_pred_rid), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "zXqn331pc1K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_rid) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_rid) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_rid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "PR1q59ICdAPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hyperparameter tuning & Cross validation\n",
        "ridge2 = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge2, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(u_train,v_train)"
      ],
      "metadata": {
        "id": "IBI7Ahpfdpnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "wmM_nbJriWvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_ridg = ridge_regressor.predict(u_test) # prediction"
      ],
      "metadata": {
        "id": "7kOF3WT3hJZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_ridg) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_ridg) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_ridg))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "LQ37y6obheKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicting values\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(v_test, v_pred_ridg, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(v_pred_ridg), max(v_test))\n",
        "p2 = min(min(v_pred_ridg), min(v_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D2_9qeG8kc8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "KnPu4eVTlQDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(u_train, v_train) #fitting model"
      ],
      "metadata": {
        "id": "PxztkamwlPWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting\n",
        "v_pred_dt = decision_tree.predict(u_test)\n",
        "v_train_dt = decision_tree.predict(u_train)"
      ],
      "metadata": {
        "id": "cS9srW7sl82u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_dt) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_dt) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_dt))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "GbxgyUSulEBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decisiontree_Dataframe = pd.DataFrame(zip(v_test, v_pred_dt), columns = ['actual', 'pred'])\n",
        "decisiontree_Dataframe"
      ],
      "metadata": {
        "id": "7DAcu5WluKci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting actual and predicted values\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(v_test, v_pred_dt, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p3 = max(max(v_pred_dt), max(v_test))\n",
        "p4 = min(min(v_pred_dt), min(v_test))\n",
        "plt.plot([p3, p4], [p3, p4], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0f5tvEqY87nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "EnumGLf8ulL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest1=RandomForestRegressor(n_estimators =500,max_depth=8)\n",
        "random_forest1.fit(u_train, v_train)"
      ],
      "metadata": {
        "id": "N0wJcRVSukpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_rf=random_forest1.predict(u_test)"
      ],
      "metadata": {
        "id": "sfND6sj9xfwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "MSE  = mean_squared_error(v_test, v_pred_rf) #Mean Squared Error\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE) #Root Mean Squared Error\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_avg #Root Mean Per Squared Error\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_rf) #R Squared & Adjusted R Squared\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(v_test,v_pred_rf))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "NmnUcrAOzqs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#showing actual and predicted values\n",
        "rf_Dataframe = pd.DataFrame(zip(v_test, v_pred_rf), columns = ['actual', 'pred'])\n",
        "rf_Dataframe"
      ],
      "metadata": {
        "id": "0zqYFjoC5jc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(v_test, v_pred_rf, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(v_pred_rf), max(v_test))\n",
        "p2 = min(min(v_pred_rf), min(v_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gb4wbZWO52zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Future Work***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "joblib.dump(random_forest1, 'regression_model.joblib')"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the File and predicting unseen data.\n",
        "regg = joblib.load('regression_model.joblib')\n",
        "predictions = regg.predict(u_test)\n",
        "predictions"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion from Model Training**\n",
        "\n",
        "We found that Sales column contains 172817 rows having 0 sale. So, i decided to create a new dataframe in which i removed rows having 0 values and tried to train our model. I used various algorithms such as Linear regression, Decision tree, Random Forest, Lasso & Ridge Regression with hyperparameter tuning and got accuracy score around 74%.\n",
        "\n",
        "I also want to see the model accuracy on total dataset(including Sales = 0 rows). So i trained another model using the same algorithms and i got accuracy near about 92% which is far better than previous model.\n",
        "\n",
        "So i came across with conclusion that removing sales rows having  0 values actually removes lot of information from dataset as it has 172817 rows which is quite large and therefore i decided not to remove those values.i got my best rmpse score from Random Forest model,i tried taking an optimum parameter so that our model doesnt overfit."
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion from EDA**\n",
        "\n",
        "- By plotting Sales vs competition Open Since Month shows sales go increasing from November and highest in the month of December.\n",
        "- By plotting Sales vs day of week, sales are highest on Monday and start declining from Tuesday to Saturday and on Sunday sales are almost near to Zero.\n",
        "- By Plotting Promotion vs Sales indicates that promotion helps in increasing Sales.\n",
        "- Types of Store plays an important role in opening pattern of stores.\n",
        "- Type b stores never closed except for refurbishment or any other reason.\n",
        "- Type b stores have comparatively having higher average sales per customer and it is mostly constant with peaks appears on weekends.\n",
        "- Assortment b is only offered by Store Type b.\n",
        "- I can observe that most of the stores remain closed during State Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that stores which are opened on State Holidays.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8vdorWb0UkUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}